"""
LangGraph å·¥ä½œæµå®šä¹‰ - ComfyUI é£æ ¼

æ ¸å¿ƒåŸåˆ™ï¼š
1. åç«¯æ˜¯æ— çŠ¶æ€æ‰§è¡Œå™¨ï¼Œåªå¤„ç†å•æ¬¡ä»»åŠ¡
2. é€šè¿‡ WebSocket æ¨é€æ‰€æœ‰ç»“æœï¼Œå‰ç«¯æ˜¯ SoT
3. æ”¯æŒè¡Œçº§æµå¼è¾“å‡º (ROW_COMPLETE)
"""
from typing import TypedDict, List, Optional, Dict, Any, Literal
from langgraph.graph import StateGraph, END
from app.core.logger import app_logger as logger
from app.core.connection_manager import manager
from app.core.protocol import EventType
from app.utils.helpers import generate_trace_id
from app.core.templates import UNSTRUCTURED_EXTRACTION_PROMPT, map_row_to_template
import json


# ========== Agent çŠ¶æ€å®šä¹‰ ==========
class AgentState(TypedDict):
    """Agent å·¥ä½œæµçŠ¶æ€ - å•æ¬¡ä»»åŠ¡"""
    # ä»»åŠ¡æ ‡è¯†
    task_id: str
    client_id: str
    task_type: Literal["extract", "audio", "chat"]
    
    # è¾“å…¥æ•°æ®
    file_content: Optional[bytes]
    file_name: Optional[str]
    text_content: Optional[str]
    
    # ä¸­é—´ç»“æœ
    ocr_text: Optional[str]
    ocr_notes: Optional[List[str]]
    content_type: Optional[str]
    extracted_rows: List[Dict[str, Any]]
    
    # è¡¨æ ¼ä¿¡æ¯
    table_id: Optional[str]
    
    # è¡¨æ ¼ä¸Šä¸‹æ–‡ï¼ˆå‰ç«¯ä¼ é€’ï¼Œç”¨äºå’¨è¯¢åˆ†æï¼‰
    table_context: Optional[Dict[str, Any]]  # {title, rows, schema, metadata}
    
    # æ§åˆ¶æµ
    next_node: Optional[str]
    error: Optional[str]


# ========== è¾…åŠ©å‡½æ•° ==========

async def push_event(client_id: str, event_type: EventType, data: dict):
    """æ¨é€ WebSocket äº‹ä»¶"""
    await manager.send(client_id, event_type, data)


async def push_row(client_id: str, table_id: str, row: dict, row_index: int):
    """æ¨é€å•è¡Œæ•°æ®"""
    logger.debug(f"[PushRow] Sending row {row_index}: {row}")
    await push_event(client_id, EventType.ROW_COMPLETE, {
        "table_id": table_id,
        "row": row,
        "row_index": row_index
    })


async def push_error(client_id: str, task_id: str, error_msg: str):
    """æ¨é€é”™è¯¯"""
    await manager.send(client_id, EventType.ERROR, {
        "task_id": task_id,
        "code": 500,
        "msg": error_msg
    })


# ========== èŠ‚ç‚¹å‡½æ•° ==========

async def router_node(state: AgentState) -> AgentState:
    """
    è·¯ç”±èŠ‚ç‚¹ - æ ¹æ®ä»»åŠ¡ç±»å‹å†³å®šä¸‹ä¸€æ­¥
    """
    task_type = state.get("task_type")
    file_name = state.get("file_name", "")
    
    logger.info(f"[Router] Task: {state['task_id']}, Type: {task_type}, File: {file_name}")
    
    # æ¨é€ä»»åŠ¡å¼€å§‹
    await push_event(state["client_id"], EventType.TASK_START, {
        "task_id": state["task_id"],
        "type": task_type,
        "message": "å¼€å§‹å¤„ç†..."
    })
    
    if task_type == "extract":
        if file_name:
            ext = file_name.lower().split('.')[-1] if '.' in file_name else ''
            if ext in ['xlsx', 'xls', 'csv']:
                state["next_node"] = "excel_node"
            elif ext in ['docx', 'doc']:
                state["next_node"] = "word_node"
            elif ext in ['pdf']:
                state["next_node"] = "ocr_node"
            elif ext in ['png', 'jpg', 'jpeg', 'webp', 'gif', 'bmp']:
                state["next_node"] = "ocr_node"
            elif ext in ['pptx', 'ppt']:
                state["next_node"] = "ocr_node"
            else:
                state["next_node"] = "ocr_node"
        else:
            state["error"] = "ç¼ºå°‘æ–‡ä»¶"
            state["next_node"] = "end"
    elif task_type == "audio":
        state["next_node"] = "audio_node"
    elif task_type == "chat":
        state["next_node"] = "chat_node"
    else:
        state["error"] = f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {task_type}"
        state["next_node"] = "end"
    
    logger.info(f"[Router] Next node: {state.get('next_node')}")
    return state


async def ocr_node(state: AgentState) -> AgentState:
    """
    OCR èŠ‚ç‚¹ - æ™ºèƒ½è§†è§‰è¯†åˆ«ï¼ˆè‡ªåŠ¨æ£€æµ‹æ‰‹å†™/æ‰“å°ä½“ï¼‰
    """
    from app.services.aliyun_ocr import ocr_service
    
    logger.info(f"[OCR] Processing task {state['task_id']}")
    
    try:
        file_content = state.get("file_content")
        if not file_content:
            raise ValueError("ç¼ºå°‘æ–‡ä»¶å†…å®¹")
        
        # 1. æ£€æµ‹å†…å®¹ç±»å‹ï¼ˆæ‰‹å†™/æ‰“å°/æ··åˆï¼‰
        # === æ™ºèƒ½åˆ†æµç­–ç•¥ï¼šé»˜è®¤èµ°å¿«é€ŸOCRï¼ˆFail-fastï¼‰ ===
        # åŸç†ï¼šä¼ ç»ŸOCRè¯†åˆ«æ‰‹å†™ä½“æ—¶ï¼Œç½®ä¿¡åº¦(avg_confidence)é€šå¸¸æä½ã€‚
        # ç­–ç•¥ï¼š
        # 1. å…ˆè·‘å¿«é€Ÿ OCR (OpenAPI)ã€‚
        # 2. å¦‚æœ ç½®ä¿¡åº¦ > 80ï¼šåˆ¤å®šä¸ºå°åˆ·ä½“ï¼Œç›´æ¥ä½¿ç”¨ã€‚
        # 3. å¦‚æœ ç½®ä¿¡åº¦ <= 80 æˆ– æ— ç»“æœï¼šåˆ¤å®šä¸ºæ‰‹å†™/ç–‘éš¾ï¼Œå›é€€ VL æ¨¡å‹ã€‚
        
        await push_event(state["client_id"], EventType.CHAT_MESSAGE, {
            "role": "agent",
            "content": "ğŸ“„ æ­£åœ¨è¿›è¡Œå°åˆ·ä½“ OCRï¼ˆå¿«è·¯å¾„ï¼‰..."
        })

        ocr_notes = []
        content_type = "printed"
        ocr_text = ""
        avg_confidence = 0.0
        low_conf_ratio = 0.0

        try:
            # è¿”å›å€¼ï¼š(æ–‡æœ¬, å¹³å‡ç½®ä¿¡åº¦, ä½åˆ†å æ¯”)
            ocr_text, avg_confidence, low_conf_ratio = await ocr_service.recognize_general(image_data=file_content)
        except Exception as e:
            logger.warning(f"[OCR] Printed OCR failed, fallback handwriting: {str(e)}")
            ocr_text = ""
            avg_confidence = 0.0
            low_conf_ratio = 1.0

        # === æ™ºèƒ½åˆ¤åˆ«é€»è¾‘ ===
        # 1. æ²¡è®¤å‡ºä¸œè¥¿ -> è‚¯å®šæ˜¯ç–‘éš¾æ‚ç—‡/æ‰‹å†™
        # 2. å±€éƒ¨ä½åˆ†å æ¯”è¿‡é«˜ (>5%) -> è¯´æ˜æœ‰æ‰‹å†™å¡«ç©º (å³ä½¿åªæœ‰å‡ ä¸ªå­—ä¹Ÿå¯èƒ½æ˜¯å…³é”®ä¿¡æ¯)
        # 3. æ•´ä½“ç½®ä¿¡åº¦è¿‡ä½ (<80) -> è¯´æ˜å›¾ç‰‡æ•´ä½“è´¨é‡å·®æˆ–å…¨æ˜¯æ½¦è‰æ‰‹å†™
        
        is_poor_quality = (
            not ocr_text or 
            low_conf_ratio > 0.05 or 
            avg_confidence < 80.0
        )
        
        if is_poor_quality:
            reason = []
            if not ocr_text: reason.append("ç»“æœä¸ºç©º")
            if low_conf_ratio > 0.05: reason.append(f"å±€éƒ¨ä½åˆ†å æ¯”é«˜({low_conf_ratio:.1%})")
            if avg_confidence < 80.0: reason.append(f"æ•´ä½“ç½®ä¿¡åº¦ä½({avg_confidence:.1f})")
            
            await push_event(state["client_id"], EventType.CHAT_MESSAGE, {
                "role": "agent",
                "content": f"âœï¸ åˆ¤å®šä¸ºæ··åˆ/æ‰‹å†™å•æ® ({', '.join(reason)})ï¼Œåˆ‡æ¢ VL æ¨¡å‹..."
            })
            content_type = "handwriting"
            ocr_text, ocr_notes = await ocr_service.recognize_order_handwriting(image_data=file_content)
        else:
            logger.info(f"[OCR] High quality (conf={avg_confidence:.1f}, low_ratio={low_conf_ratio:.1%}), skipping VL.")
        
        state["ocr_text"] = ocr_text
        state["ocr_notes"] = ocr_notes  # ä¿å­˜è¯†åˆ«å¤‡æ³¨ä¾›åç»­æ ¡å¯¹å‚è€ƒ
        state["content_type"] = content_type
        
        # 3. å¦‚æœæœ‰è¯†åˆ«å¤‡æ³¨ï¼Œé€šçŸ¥å‰ç«¯
        if ocr_notes:
            await push_event(state["client_id"], EventType.CHAT_MESSAGE, {
                "role": "agent",
                "content": f"ğŸ“‹ è¯†åˆ«å¤‡æ³¨: {'; '.join(ocr_notes)}"
            })
        
        logger.info(f"[OCR] Result ({content_type}): {ocr_text[:100] if ocr_text else 'empty'}...")
        
        state["next_node"] = "llm_node"
        
    except Exception as e:
        logger.error(f"[OCR] Failed: {str(e)}")
        state["error"] = str(e)
        state["next_node"] = "end"
    
    return state


async def excel_node(state: AgentState) -> AgentState:
    """
    Excel èŠ‚ç‚¹ - ä½¿ç”¨ FastTools è§£æ Excel/CSVï¼Œè½¬ä¸ºæ–‡æœ¬äº¤ç»™ LLM æ ‡å‡†åŒ–
    """
    from app.agents.tools.fast_tools import fast_tools
    import json
    
    logger.info(f"[Excel] Processing task {state['task_id']}")
    
    try:
        file_content = state.get("file_content")
        file_name = state.get("file_name", "")
        
        if not file_content:
            raise ValueError("ç¼ºå°‘æ–‡ä»¶å†…å®¹")
        
        # ä½¿ç”¨ FastTools è§£æ
        result = fast_tools.parse_excel(file_content, file_name)
        
        if result.success and result.rows:
            # å°†æå–çš„è¡Œè½¬æ¢ä¸º JSON å­—ç¬¦ä¸²æˆ– Markdownï¼Œäº¤ç»™ LLM è¿›è¡Œæ ‡å‡†åŒ–æ¸…æ´—
            # è¿™æ ·èƒ½è‡ªåŠ¨å¤„ç†åºå·ã€è§„æ ¼/å•ä½æ‹†åˆ†ç­‰é€»è¾‘
            state["ocr_text"] = json.dumps(result.rows, ensure_ascii=False)
            state["next_node"] = "llm_node"
            logger.info(f"[Excel] Parsed {len(result.rows)} rows, passing to LLM for standardization")
        else:
            state["error"] = result.message or "Excel è§£æå¤±è´¥æˆ–ä¸ºç©º"
            state["next_node"] = "end"
        
    except Exception as e:
        logger.error(f"[Excel] Failed: {str(e)}")
        state["error"] = str(e)
        state["next_node"] = "end"
    
    return state


async def word_node(state: AgentState) -> AgentState:
    """
    Word èŠ‚ç‚¹ - ä½¿ç”¨ FastTools è§£æ Word æ–‡æ¡£ï¼Œå†…å®¹äº¤ç»™ LLM
    """
    from app.agents.tools.fast_tools import fast_tools
    import json
    
    logger.info(f"[Word] Processing task {state['task_id']}")
    
    try:
        file_content = state.get("file_content")
        if not file_content:
            raise ValueError("ç¼ºå°‘æ–‡ä»¶å†…å®¹")
        
        # ä½¿ç”¨ FastTools è§£æ
        result = fast_tools.parse_word(file_content)
        
        if result.success:
            content_for_llm = ""
            if result.rows:
                # è¡¨æ ¼å†…å®¹è½¬ JSON å­—ç¬¦ä¸²
                content_for_llm = json.dumps(result.rows, ensure_ascii=False)
                logger.info(f"[Word] Extracted {len(result.rows)} rows from tables")
            elif result.message:
                # çº¯æ–‡æœ¬å†…å®¹
                content_for_llm = result.message
                logger.info(f"[Word] Extracted text content")
            
            if content_for_llm:
                state["ocr_text"] = content_for_llm
                state["next_node"] = "llm_node"
            else:
                state["error"] = "Word æ–‡æ¡£å†…å®¹ä¸ºç©º"
                state["next_node"] = "end"
        else:
            state["error"] = result.message
            state["next_node"] = "end"
        
    except Exception as e:
        logger.error(f"[Word] Failed: {str(e)}")
        state["error"] = str(e)
        state["next_node"] = "end"
    
    return state


async def llm_node(state: AgentState) -> AgentState:
    """
    LLM èŠ‚ç‚¹ - å°†æ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ– JSON
    """
    from app.agents.nodes.llm_node import format_to_json
    
    logger.info(f"[LLM] Processing task {state['task_id']}")
    
    try:
        ocr_text = state.get("ocr_text", "")
        if not ocr_text:
            raise ValueError("æ²¡æœ‰å¾…å¤„ç†çš„æ–‡æœ¬")
        
        await push_event(state["client_id"], EventType.CHAT_MESSAGE, {
            "role": "agent",
            "content": "æ­£åœ¨æå–ç»“æ„åŒ–æ•°æ®..."
        })
        
        # æ ¼å¼åŒ–ä¸º JSON
        rows = []
        async for row in format_to_json(ocr_text):
            if "_error" not in row:
                rows.append(row)
        
        state["extracted_rows"] = rows
        state["next_node"] = "push_rows_node"
        
        logger.info(f"[LLM] Extracted {len(rows)} rows")
        
    except Exception as e:
        logger.error(f"[LLM] Failed: {str(e)}")
        state["error"] = str(e)
        state["next_node"] = "end"
    
    return state


async def push_rows_node(state: AgentState) -> AgentState:
    """
    æ¨é€è¡ŒèŠ‚ç‚¹ - é€è¡Œæ¨é€æ•°æ®åˆ°å‰ç«¯
    """
    from app.core.templates import DEFAULT_SCHEMA, map_row_to_template
    
    logger.info(f"[PushRows] Task {state['task_id']}")
    
    raw_rows = state.get("extracted_rows", [])
    table_id = state.get("table_id")
    client_id = state["client_id"]
    
    if not raw_rows:
        await push_event(client_id, EventType.CHAT_MESSAGE, {
            "role": "agent",
            "content": "âš ï¸ æœªèƒ½æå–åˆ°æœ‰æ•ˆæ•°æ®"
        })
        state["next_node"] = "end"
        return state
    
    # å¼ºåˆ¶ä½¿ç”¨å›ºå®š Schema
    schema = DEFAULT_SCHEMA
    
    # å‘é€ TABLE_REPLACE æ¥æ›´æ–° schemaï¼ˆä½¿ç”¨ç©ºæ•°æ®ï¼‰ï¼Œè®©å‰ç«¯å‡†å¤‡å¥½æ¥æ”¶
    if table_id:
        await push_event(client_id, EventType.TABLE_REPLACE, {
            "table_id": table_id,
            "rows": [],  # å…ˆæ¸…ç©ºï¼Œåé¢é€è¡Œæ·»åŠ 
            "schema": schema,
        })
    else:
        # ç”Ÿæˆä¸€ä¸ªçœŸå®çš„ table_id
        import time
        table_id = f"sheet_{int(time.time() * 1000)}"
        
        # åˆ›å»ºæ–°è¡¨ï¼Œå‘é€çœŸå®çš„ table_id
        await push_event(client_id, EventType.TABLE_CREATE, {
            "table_id": table_id,
            "title": f"å¯¼å…¥æ•°æ® - {state.get('file_name', 'æœªå‘½å')}",
            "source": state.get("file_name"),
            "schema": schema,
        })
        # è®°å½•å› stateï¼Œä¾¿äº TASK_FINISH / åç»­èŠ‚ç‚¹ä½¿ç”¨
        state["table_id"] = table_id
    
    # é€è¡Œæ¸…æ´—å¹¶æ¨é€
    valid_rows = []
    for idx, raw_row in enumerate(raw_rows):
        # è°ƒè¯•ï¼šæ‰“å°åŸå§‹ key çš„ hexï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ä¸å¯è§å­—ç¬¦
        if idx == 0:
            logger.debug(f"[PushRows] First row keys hex: {{k: k.encode('utf-8').hex() for k in raw_row.keys()}}")
            
        # æ— è®ºæ•°æ®æ¥æºï¼ˆExcel/OCRï¼‰ï¼Œéƒ½æ˜ å°„åˆ°æ ‡å‡†æ¨¡æ¿
        normalized_row = map_row_to_template(raw_row)
        await push_row(client_id, table_id, normalized_row, idx)
        valid_rows.append(normalized_row)
    
    # æ›´æ–° state ä¸­çš„ extracted_rows ä¸ºæ ‡å‡†åŒ–åçš„æ•°æ®ï¼Œä¾› calibration_node ä½¿ç”¨
    state["extracted_rows"] = valid_rows
    
    await push_event(client_id, EventType.CHAT_MESSAGE, {
        "role": "agent",
        "content": f"âœ… å·²æå– {len(valid_rows)} è¡Œæ•°æ®ï¼ˆå…ˆå¡«è¡¨ï¼Œåå°æ ¡å¯¹ä¸­â€¦ï¼‰"
    })

    # === å…³é”®æ”¹åŠ¨ï¼šæ ¡å¯¹æ”¹ä¸ºåå°å¼‚æ­¥ï¼Œä¸é˜»å¡â€œå¡«è¡¨å®Œæˆâ€çš„è§†è§‰åé¦ˆ ===
    # è¿™æ ·å‰ç«¯ä¼šæ›´å¿«æ”¶åˆ° TASK_FINISHï¼ˆå¹¶åœæ­¢ isStreamingï¼‰ï¼Œæ ¡å¯¹ç»“æœéšåé€æ¡æ¨é€ã€‚
    import asyncio

    async def _run_calibration_background(cal_state: AgentState):
        try:
            # å¤ç”¨ç°æœ‰æ ¡å¯¹èŠ‚ç‚¹é€»è¾‘
            await calibration_node(cal_state)
        except Exception as e:
            logger.error(f"[CalibrationBg] Failed: {str(e)}")
            await push_event(cal_state["client_id"], EventType.CHAT_MESSAGE, {
                "role": "agent",
                "content": f"âš ï¸ æ ¡å¯¹æµç¨‹å¼‚å¸¸ï¼ˆä¸å½±å“å¡«è¡¨ï¼‰ï¼š{str(e)}"
            })

    # ä»…ä¿ç•™æ ¡å¯¹æ‰€éœ€å­—æ®µï¼Œé¿å…æŠŠå¤§æ–‡ä»¶å†…å®¹å¸¦å…¥åå°ä»»åŠ¡
    cal_state: AgentState = {
        "task_id": state["task_id"],
        "client_id": state["client_id"],
        "task_type": state["task_type"],
        "file_content": None,
        "file_name": state.get("file_name"),
        "text_content": state.get("text_content"),
        "ocr_text": state.get("ocr_text"),
        "ocr_notes": state.get("ocr_notes"),
        "content_type": state.get("content_type"),
        "extracted_rows": valid_rows,
        "table_id": table_id,
        "table_context": state.get("table_context"),
        "next_node": None,
        "error": None,
    }
    asyncio.create_task(_run_calibration_background(cal_state))

    # ç›´æ¥ç»“æŸä»»åŠ¡ï¼ˆä¸ç­‰æ ¡å¯¹ï¼‰
    state["next_node"] = "end"
    return state


async def calibration_node(state: AgentState) -> AgentState:
    """
    æ ¡å‡†èŠ‚ç‚¹ - åˆ†æµå¤„ç†æ‰“å°ä½“/æ‰‹å†™ä½“
    
    ã€æ‰“å°ä½“ã€‘çº¯ç¨‹åºå¤„ç†ï¼ˆæå¿«ï¼‰ï¼š
    - ç²¾ç¡®åŒ¹é… â†’ ç›´æ¥å¡«å…¥"è®¢å•å•†å“"
    - æ¨¡ç³ŠåŒ¹é… â†’ æ˜¾ç¤ºå¤šä¸ªå€™é€‰
    
    ã€æ‰‹å†™ä½“ã€‘ç¨‹åº + Turboï¼š
    - ç²¾ç¡®åŒ¹é… â†’ ç›´æ¥å¡«å…¥"è®¢å•å•†å“"
    - æ¨¡ç³Šå€™é€‰ + Turbo æ¨æ–­ â†’ æ™ºèƒ½æ¨æ–­ç»“æœ
    """
    from app.services.knowledge_base import vector_store
    from app.services.aliyun_llm import llm_service
    from app.core.templates import HANDWRITING_CALIBRATION_PROMPT
    
    logger.info(f"[Calibration] Task {state['task_id']}")
    
    rows = state.get("extracted_rows", [])
    client_id = state["client_id"]
    table_id = state.get("table_id", "new")
    content_type = state.get("content_type", "printed")  # é»˜è®¤ä¸ºæ‰“å°ä½“
    
    if not rows:
        state["next_node"] = "end"
        return state
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºæ‰‹å†™ä½“
    is_handwriting = content_type in ["handwriting", "mixed"]
    
    await push_event(client_id, EventType.CHAT_MESSAGE, {
        "role": "agent",
        "content": f"ğŸ” æ­£åœ¨æ ¡å¯¹... ({'æ‰‹å†™è¯†åˆ«æ¨¡å¼' if is_handwriting else 'æ‰“å°è¯†åˆ«æ¨¡å¼'})"
    })
    
    product_field = "è¯†åˆ«å•†å“"
    exact_match_count = 0
    fuzzy_match_count = 0
    need_llm_items = []  # æ‰‹å†™ä½“éœ€è¦ LLM æ¨æ–­çš„é¡¹
    
    # === ç¨‹åºå¿«é€ŸåŒ¹é…ï¼ˆæ‰“å°ä½“å’Œæ‰‹å†™ä½“éƒ½å…ˆæ‰§è¡Œï¼‰===
    for idx, row in enumerate(rows):
        product_name = str(row.get(product_field, "")).strip()
        order_product = ""
        note = ""
        
        if not product_name:
            continue
        
        try:
            # å°è¯•ä»çŸ¥è¯†åº“åŒ¹é…
            result = await vector_store.calibrate(product_name)
            
            # ç²¾ç¡®åŒ¹é…ï¼ˆç½®ä¿¡åº¦ > 0.95ï¼‰
            if result.confidence >= 0.95:
                order_product = result.calibrated
                exact_match_count += 1
                if result.product and result.product.price == 0:
                    note = "âš ï¸ æ— ä»·æ ¼"
            
            # é«˜ç½®ä¿¡åº¦æ¨¡ç³ŠåŒ¹é…ï¼ˆ0.8 - 0.95ï¼‰
            elif result.confidence >= 0.8:
                order_product = result.calibrated
                fuzzy_match_count += 1
            
            # ä¸­ç­‰ç½®ä¿¡åº¦ï¼ˆ0.5 - 0.8ï¼‰
            elif result.confidence >= 0.5:
                if is_handwriting:
                    # æ‰‹å†™ä½“ï¼šæ”¶é›†å€™é€‰ï¼Œäº¤ç»™ LLM æ¨æ–­
                    candidates = [result.calibrated] + (result.candidates or [])[:4]
                    need_llm_items.append({
                        "idx": idx,
                        "original": product_name,
                        "candidates": candidates
                    })
                    order_product = f"â³ AIåˆ†æä¸­..."
                else:
                    # æ‰“å°ä½“ï¼šç›´æ¥æ˜¾ç¤ºå€™é€‰
                    candidates = [result.calibrated] + (result.candidates or [])[:2]
                    order_product = f"â“ å¯èƒ½: {' / '.join(candidates)}"
                    fuzzy_match_count += 1
            
            # ä½ç½®ä¿¡åº¦ï¼ˆ0.3 - 0.5ï¼‰
            elif result.confidence >= 0.3:
                if is_handwriting and result.candidates:
                    # æ‰‹å†™ä½“ï¼šæ”¶é›†å€™é€‰ï¼Œäº¤ç»™ LLM
                    need_llm_items.append({
                        "idx": idx,
                        "original": product_name,
                        "candidates": result.candidates[:5]
                    })
                    order_product = f"â³ AIåˆ†æä¸­..."
                elif result.candidates:
                    # æ‰“å°ä½“ï¼šæ˜¾ç¤ºå¤šä¸ªå€™é€‰
                    order_product = f"â“ å¯èƒ½: {' / '.join(result.candidates[:3])}"
                else:
                    order_product = "âŒ æœªæ‰¾åˆ°åŒ¹é…"
            
            # æä½ç½®ä¿¡åº¦ï¼ˆ< 0.3ï¼‰
            else:
                if is_handwriting:
                    # æ‰‹å†™ä½“ï¼šå³ä½¿æ²¡æœ‰å€™é€‰ä¹Ÿå°è¯•è®© LLM åˆ†æ
                    need_llm_items.append({
                        "idx": idx,
                        "original": product_name,
                        "candidates": result.candidates[:5] if result.candidates else []
                    })
                    order_product = f"â³ AIåˆ†æä¸­..."
                else:
                    order_product = "âŒ åº“ä¸­æœªæ‰¾åˆ°"
                    
        except Exception as e:
            logger.debug(f"[Calibration] Match failed for row {idx}: {str(e)}")
            order_product = "â“ åŒ¹é…å¼‚å¸¸"
        
        # æ¨é€æ ¡å¯¹ç»“æœ
        if order_product:
            await push_event(client_id, EventType.CELL_UPDATE, {
                "table_id": table_id,
                "row_index": idx,
                "col_key": "è®¢å•å•†å“",
                "value": order_product
            })
        
        if note:
            await push_event(client_id, EventType.CELL_UPDATE, {
                "table_id": table_id,
                "row_index": idx,
                "col_key": "_calibration_note",
                "value": note
            })
    
    # === æ‰‹å†™ä½“ï¼šLLM æ™ºèƒ½æ¨æ–­ ===
    if need_llm_items and is_handwriting:
        await push_event(client_id, EventType.CHAT_MESSAGE, {
            "role": "agent",
            "content": f"ğŸ¤– AI æ­£åœ¨åˆ†æ {len(need_llm_items)} ä¸ªæ‰‹å†™å•†å“å..."
        })
        
        for item in need_llm_items:
            try:
                candidates_str = "\n".join([f"- {c}" for c in item['candidates']]) if item['candidates'] else "ï¼ˆæ— å€™é€‰ï¼‰"
                
                prompt = HANDWRITING_CALIBRATION_PROMPT.format(
                    recognized_name=item['original'],
                    candidates=candidates_str
                )
                
                # è°ƒç”¨ Turbo æ¨¡å‹æ¨æ–­
                llm_result = await llm_service.call_turbo_model(
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯å•†å“åç§°æ ¡å¯¹ä¸“å®¶ï¼Œæ“…é•¿åˆ†ææ‰‹å†™å­—è¿¹ã€‚åªè¾“å‡º JSONã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.1
                )
                
                # è§£æ LLM ç»“æœ
                order_product = _parse_calibration_result(llm_result, item['original'])
                
                await push_event(client_id, EventType.CELL_UPDATE, {
                    "table_id": table_id,
                    "row_index": item['idx'],
                    "col_key": "è®¢å•å•†å“",
                    "value": order_product
                })
                
            except Exception as e:
                logger.error(f"[Calibration] LLM failed for row {item['idx']}: {str(e)}")
                await push_event(client_id, EventType.CELL_UPDATE, {
                    "table_id": table_id,
                    "row_index": item['idx'],
                    "col_key": "è®¢å•å•†å“",
                    "value": "âŒ AIåˆ†æå¤±è´¥"
                })
    
    # æ±‡æ€»é€šçŸ¥
    total_rows = len(rows)
    summary_parts = []
    if exact_match_count > 0:
        summary_parts.append(f"ç²¾ç¡®åŒ¹é… {exact_match_count} é¡¹")
    if fuzzy_match_count > 0:
        summary_parts.append(f"æ¨¡ç³ŠåŒ¹é… {fuzzy_match_count} é¡¹")
    if need_llm_items:
        summary_parts.append(f"AIæ¨æ–­ {len(need_llm_items)} é¡¹")
    
    summary = "ã€".join(summary_parts) if summary_parts else "æ— åŒ¹é…"
    
    await push_event(client_id, EventType.CHAT_MESSAGE, {
        "role": "agent",
        "content": f"âœ… æ ¡å¯¹å®Œæˆ: {total_rows} è¡Œæ•°æ® ({summary})"
    })
    
    state["next_node"] = "end"
    return state


def _parse_calibration_result(llm_result: str, original: str) -> str:
    """è§£æ LLM æ ¡å¯¹ç»“æœ"""
    import json
    
    try:
        # å°è¯•è§£æ JSON
        result = llm_result.strip()
        if result.startswith("```"):
            result = result.split("```")[1]
            if result.startswith("json"):
                result = result[4:]
        
        data = json.loads(result)
        
        if data.get("match"):
            confidence = data.get("confidence", "ä¸­")
            if confidence == "é«˜":
                return data["match"]
            else:
                return f"âœ… {data['match']}"
        elif data.get("candidates"):
            return f"â“ å¯èƒ½: {' / '.join(data['candidates'][:3])}"
        elif data.get("note"):
            return f"âŒ {data['note']}"
        else:
            return f"â“ {original}"
            
    except Exception:
        # JSON è§£æå¤±è´¥ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨æ–‡æœ¬
        if "âœ…" in llm_result or "â†’" in llm_result:
            return llm_result.strip()[:50]
        elif "â“" in llm_result:
            return llm_result.strip()[:50]
        elif "âŒ" in llm_result:
            return llm_result.strip()[:50]
        else:
            return f"â“ {original}"


async def audio_node(state: AgentState) -> AgentState:
    """
    éŸ³é¢‘èŠ‚ç‚¹ - è¯­éŸ³è¯†åˆ«å’ŒæŒ‡ä»¤å¤„ç†
    """
    from app.services.aliyun_asr import asr_service
    from app.services.aliyun_llm import llm_service
    
    logger.info(f"[Audio] Processing task {state['task_id']}")
    
    try:
        file_content = state.get("file_content")
        if not file_content:
            raise ValueError("ç¼ºå°‘éŸ³é¢‘å†…å®¹")
        
        # ASR è¯†åˆ«
        asr_text = await asr_service.recognize_audio(file_content)
        logger.info(f"[Audio] ASR result: {asr_text}")
        
        # æ¨é€ç”¨æˆ·è¯­éŸ³æ–‡æœ¬
        await push_event(state["client_id"], EventType.CHAT_MESSAGE, {
            "role": "user",
            "content": asr_text,
            "is_voice": True
        })
        
        # LLM ç†è§£æŒ‡ä»¤
        system_prompt = """ä½ æ˜¯æ™ºèƒ½è¡¨å•åŠ©æ‰‹ã€‚åˆ†æç”¨æˆ·æŒ‡ä»¤ï¼Œè¾“å‡º JSON å·¥å…·è°ƒç”¨ã€‚

å¯ç”¨å·¥å…·ï¼š
- update_cell: {"tool": "update_cell", "params": {"row_index": 0, "key": "å­—æ®µå", "value": "æ–°å€¼"}}
- add_row: {"tool": "add_row", "params": {"data": {"product": "å•†å“", "quantity": 10}}}
- delete_row: {"tool": "delete_row", "params": {"row_index": 0}}

å¦‚æœä¸æ˜¯æ“ä½œæŒ‡ä»¤ï¼Œç›´æ¥å›å¤æ–‡æœ¬ã€‚"""
        
        response = await llm_service.call_main_model([
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": asr_text}
        ])
        
        # è§£æå“åº”
        clean = response.strip().replace("```json", "").replace("```", "").strip()
        
        if clean.startswith("{") and "tool" in clean:
            try:
                tool_call = json.loads(clean)
                tool_name = tool_call.get("tool")
                params = tool_call.get("params", {})
                
                await push_event(state["client_id"], EventType.TOOL_CALL, {
                    "tool": tool_name,
                    "params": params
                })
                
                await push_event(state["client_id"], EventType.CHAT_MESSAGE, {
                    "role": "agent",
                    "content": f"å·²æ‰§è¡Œ: {tool_name}"
                })
            except json.JSONDecodeError:
                await push_event(state["client_id"], EventType.CHAT_MESSAGE, {
                    "role": "agent",
                    "content": response
                })
        else:
            await push_event(state["client_id"], EventType.CHAT_MESSAGE, {
                "role": "agent",
                "content": response
            })
        
    except Exception as e:
        logger.error(f"[Audio] Failed: {str(e)}")
        state["error"] = str(e)
    
    state["next_node"] = "end"
    return state


async def chat_node(state: AgentState) -> AgentState:
    """
    èŠå¤©èŠ‚ç‚¹ - ä½¿ç”¨ Function Calling è®©å¤§æ¨¡å‹å†³å®šè°ƒç”¨å·¥å…·
    
    æµç¨‹ï¼š
    1. æ‰€æœ‰ç”¨æˆ·æ¶ˆæ¯ + å·¥å…·å®šä¹‰ å‘ç»™ä¸»æ§å¤§æ¨¡å‹
    2. å¤§æ¨¡å‹å†³å®šï¼šè°ƒç”¨å·¥å…· or ç›´æ¥å›å¤
    3. å¦‚æœè°ƒç”¨å·¥å…·ï¼Œæ‰§è¡Œåè¿”å›ç»“æœç»™ç”¨æˆ·
    """
    from app.services.aliyun_llm import llm_service
    from app.agents.context_manager import context_manager
    from app.agents.tools.fast_tools import fast_tools
    
    logger.info(f"[Chat] Processing task {state['task_id']}")
    
    client_id = state["client_id"]
    text = state.get("text_content", "")
    table_context = state.get("table_context")
    table_id = state.get("table_id")
    
    try:
        if not text:
            raise ValueError("ç¼ºå°‘èŠå¤©å†…å®¹")
        
        # è·å–ä¼šè¯ä¸Šä¸‹æ–‡
        ctx = context_manager.get_context(client_id)
        ctx.add_user_message(text)
        
        # æ„å»ºè¡¨æ ¼ä¸Šä¸‹æ–‡æè¿°
        table_info = "ã€å½“å‰ç”»å¸ƒä¸Šçš„è¡¨æ ¼ã€‘\n"
        if table_context and table_context.get("tables"):
            tables = table_context.get("tables", {})
            active_table_id = table_context.get("activeTableId")
            
            if not tables:
                table_info += "æš‚æ— è¡¨æ ¼\n"
            else:
                for idx, (tid, table) in enumerate(tables.items()):
                    rows = table.get("rows", [])
                    is_active = "(å½“å‰æ¿€æ´»)" if tid == active_table_id else ""
                    table_info += f"{idx+1}. ID: {tid} | æ ‡é¢˜: {table.get('title', 'æœªå‘½å')} | {len(rows)} è¡Œæ•°æ® {is_active}\n"
                    
                    # å¦‚æœæ˜¯æ¿€æ´»çš„è¡¨æ ¼ï¼Œå±•ç¤ºéƒ¨åˆ†æ•°æ®ä½œä¸ºå‚è€ƒ
                    if tid == active_table_id and rows:
                        sample_rows = rows[:3]
                        table_info += f"   ç¤ºä¾‹æ•°æ®: {json.dumps(sample_rows, ensure_ascii=False)[:500]}\n"
        else:
            table_info += "æš‚æ— è¡¨æ ¼ä¿¡æ¯\n"
        
        # ç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯æ™ºèƒ½è®¢å•åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·å¤„ç†è®¢å•å’Œå•†å“æ•°æ®ã€‚

ã€å¯¹è¯å†å²ã€‘
{ctx.get_context_for_llm(n=5)}
{table_info}

ã€é‡è¦è§„åˆ™ã€‘
- **é»˜è®¤è¡¨æ ¼**ï¼šç”¨æˆ·æœªæ˜ç¡®æŒ‡å®šè¡¨æ ¼æ—¶ï¼Œæ‰€æœ‰æ“ä½œé»˜è®¤åœ¨"å½“å‰æ¿€æ´»"çš„è¡¨æ ¼ä¸Šæ‰§è¡Œï¼Œæ— éœ€è¯¢é—®ç”¨æˆ·ã€‚
- **è¡Œå·è§„åˆ™**ï¼š"ç¬¬ä¸€è¡Œ"å¯¹åº” row_index=1ï¼Œ"ç¬¬äºŒè¡Œ"å¯¹åº” row_index=2ï¼Œä»¥æ­¤ç±»æ¨ã€‚

ã€ä½ å¯ä»¥åšçš„ã€‘
- **æ™ºèƒ½å¡«è¡¨**ï¼šå¦‚æœç”¨æˆ·å‘æ¥ä¸€æ®µåŒ…å«å•†å“å’Œæ•°é‡çš„æ–‡æœ¬ï¼ˆå¦‚"åœŸè±† 50æ–¤ï¼Œç™½èœ 20æ–¤"ï¼‰ï¼Œè¯·ç›´æ¥è°ƒç”¨ `smart_fill` å·¥å…·ï¼Œå°†ç”¨æˆ·è¾“å…¥çš„åŸå§‹æ–‡æœ¬åŸæ ·ä¼ è¿›å»ï¼Œä¸è¦è‡ªè¡Œæå–ã€‚
- **æŸ¥è¯¢å•†å“**ï¼šå¦‚æœç”¨æˆ·é—®"æœ‰æ²¡æœ‰åœŸè±†"æˆ–"åœŸè±†å¤šå°‘é’±"ï¼Œè¯·è°ƒç”¨ `query_product`ã€‚
- **æ“ä½œè¡¨æ ¼**ï¼šæ–°å»ºè¡¨æ ¼ã€æ·»åŠ è¡Œã€åˆ é™¤è¡Œã€ä¿®æ”¹å•å…ƒæ ¼ï¼ˆä¸ç”¨ä¼  table_idï¼Œé»˜è®¤æ“ä½œå½“å‰è¡¨æ ¼ï¼‰ã€‚
- **ç»Ÿè®¡è®¡ç®—**ï¼šè®¡ç®—æ€»ä»·ã€æ•°é‡åˆè®¡ç­‰ã€‚
- é—²èŠå’¨è¯¢ç›´æ¥å›å¤å³å¯ã€‚

ã€æš‚ä¸æ”¯æŒçš„æ“ä½œã€‘
ä»¥ä¸‹æ“ä½œéœ€è¦ç”¨æˆ·æ‰‹åŠ¨åœ¨ç•Œé¢ä¸Šå®Œæˆï¼Œå¦‚æœç”¨æˆ·å°è¯•è¿™äº›æ“ä½œï¼Œè¯·å‹å¥½æç¤ºï¼š
- å¯¼å‡ºè¡¨æ ¼/ä¸‹è½½è®¢å• â†’ è¯·ç‚¹å‡»é¡¶éƒ¨"å¯¼å‡ºå…¨éƒ¨"æŒ‰é’®ï¼Œæˆ–å³é”®èœå•"å¯¼å‡ºæ­¤ Sheet"
- å…³é—­/åˆ é™¤è¡¨æ ¼ â†’ è¯·ç‚¹å‡» Tab é¡µç­¾ä¸Šçš„ X æŒ‰é’®
- ä¿®æ”¹è®¢å•æ—¥æœŸ/æ—¶é—´ â†’ è¯·åœ¨è¡¨æ ¼ä¸Šæ–¹çš„æ—¶é—´è¾“å…¥æ¡†ä¸­ä¿®æ”¹
- é€‰æ‹©å®¢æˆ·/é¤å…/è®¢å•ç±»å‹ â†’ è¯·ä½¿ç”¨è¡¨æ ¼ä¸Šæ–¹çš„ä¸‹æ‹‰æ¡†é€‰æ‹©

ç”¨ç®€æ´å‹å¥½çš„ä¸­æ–‡å›å¤ã€‚"""

        # å®šä¹‰å¯ç”¨å·¥å…·
        tools = _get_chat_tools()
        
        # è°ƒç”¨å¸¦å·¥å…·çš„ä¸»æ§å¤§æ¨¡å‹
        result = await llm_service.call_with_tools(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": text}
            ],
            tools=tools
        )
        
        # å¤„ç†ç»“æœ
        if result.get("tool_calls"):
            # å¤§æ¨¡å‹å†³å®šè°ƒç”¨å·¥å…·
            tool_responses = []
            for tool_call in result["tool_calls"]:
                tool_name = tool_call["name"]
                tool_args = tool_call.get("arguments", {})
                
                # è§£æå‚æ•°ï¼ˆå¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²ï¼‰
                if isinstance(tool_args, str):
                    try:
                        tool_args = json.loads(tool_args)
                    except:
                        tool_args = {}
                
                logger.info(f"[Chat] Executing tool: {tool_name} with args: {tool_args}")
                
                # æ‰§è¡Œå·¥å…·
                tool_result = await _execute_tool(
                    tool_name, tool_args, client_id, table_id, table_context, fast_tools
                )
                tool_responses.append(tool_result)
            
            # åˆå¹¶å·¥å…·ç»“æœä½œä¸ºå›å¤
            final_response = "\n\n".join(tool_responses)
        else:
            # ç›´æ¥ä½¿ç”¨æ–‡æœ¬å›å¤
            final_response = result.get("content", "")
        
        if final_response:
            await push_event(client_id, EventType.CHAT_MESSAGE, {
                "role": "agent",
                "content": final_response
            })
            ctx.add_agent_message(final_response)
        
    except Exception as e:
        logger.error(f"[Chat] Failed: {str(e)}")
        await push_event(client_id, EventType.CHAT_MESSAGE, {
            "role": "agent",
            "content": f"æŠ±æ­‰ï¼Œå¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™äº†ï¼š{str(e)}"
        })
        state["error"] = str(e)
    
    state["next_node"] = "end"
    return state


def _get_chat_tools() -> List[Dict]:
    """è·å–èŠå¤©å¯ç”¨çš„å·¥å…·å®šä¹‰"""
    return [
        {
            "type": "function",
            "function": {
                "name": "create_table",
                "description": "åˆ›å»ºä¸€ä¸ªæ–°çš„è¡¨æ ¼ã€‚å½“ç”¨æˆ·è¯´'æ–°å»ºè¡¨æ ¼'ã€'åˆ›å»ºè¡¨æ ¼'ã€'å»ºä¸€ä¸ªè¡¨'æ—¶è°ƒç”¨",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "title": {
                            "type": "string",
                            "description": "è¡¨æ ¼æ ‡é¢˜ï¼Œå¦‚'å•†å“è®¢å•'ã€'é‡‡è´­æ¸…å•'"
                        }
                    },
                    "required": []
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "smart_fill",
                "description": "æ™ºèƒ½å¡«è¡¨å·¥å…·ã€‚å½“ç”¨æˆ·åœ¨å¯¹è¯ä¸­å‘é€ä¸€æ®µåŒ…å«è®¢å•ä¿¡æ¯çš„æ–‡æœ¬ï¼ˆå¦‚'æˆ‘è¦åœŸè±†50æ–¤ï¼Œç™½èœ30æ–¤...'ï¼‰æ—¶è°ƒç”¨ã€‚è¯·å°†ç”¨æˆ·çš„åŸå§‹æ–‡æœ¬ç›´æ¥ä¼ ç»™æ­¤å·¥å…·ï¼Œä¸è¦è‡ªè¡Œæå–ã€‚",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "text": {
                            "type": "string",
                            "description": "ç”¨æˆ·è¾“å…¥çš„åŸå§‹è®¢å•æ–‡æœ¬"
                        },
                        "table_id": {
                            "type": "string",
                            "description": "ç›®æ ‡è¡¨æ ¼IDï¼ˆå¯é€‰ï¼‰"
                        }
                    },
                    "required": ["text"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "query_product",
                "description": "ä»å•†å“åº“ä¸­æŸ¥è¯¢å•†å“ä¿¡æ¯ã€‚å½“ç”¨æˆ·é—®'æœ‰æ²¡æœ‰XX'ã€'æŸ¥ä¸€ä¸‹XX'ã€'XXå¤šå°‘é’±'æ—¶è°ƒç”¨",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "product_name": {
                            "type": "string",
                            "description": "è¦æŸ¥è¯¢çš„å•†å“åç§°"
                        }
                    },
                    "required": ["product_name"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "calculate_total",
                "description": "è®¡ç®—è¡¨æ ¼æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯ã€‚å½“ç”¨æˆ·é—®'æ€»å…±å¤šå°‘é’±'ã€'åˆè®¡'ã€'ç»Ÿè®¡'æ—¶è°ƒç”¨",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "operation": {
                            "type": "string",
                            "enum": ["total", "count", "average"],
                            "description": "è®¡ç®—ç±»å‹ï¼štotal(æ€»ä»·), count(æ•°é‡), average(å¹³å‡)"
                        }
                    },
                    "required": []
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "modify_cell",
                "description": "ä¿®æ”¹è¡¨æ ¼ä¸­çš„æŸä¸ªå•å…ƒæ ¼ã€‚å½“ç”¨æˆ·è¯´'æŠŠXXæ”¹æˆYY'ã€'ä¿®æ”¹ç¬¬Xè¡Œ'æ—¶è°ƒç”¨",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "table_id": {
                            "type": "string",
                            "description": "ç›®æ ‡è¡¨æ ¼IDã€‚å¦‚æœä¸æŒ‡å®šï¼Œé»˜è®¤æ“ä½œå½“å‰æ¿€æ´»çš„è¡¨æ ¼ï¼›å¦‚æœç”¨æˆ·æŒ‡å®šäº†ç‰¹å®šè¡¨æ ¼ï¼ˆå¦‚'é‡‡è´­å•'ï¼‰ï¼Œè¯·ä¼ å…¥å¯¹åº”çš„ID"
                        },
                        "row_index": {
                            "type": "integer",
                            "description": "è¡Œå·ï¼ˆä»1å¼€å§‹ï¼‰"
                        },
                        "column": {
                            "type": "string",
                            "description": "åˆ—åï¼Œå¦‚'å•†å“åç§°'ã€'æ•°é‡'ã€'å•ä»·'"
                        },
                        "value": {
                            "type": "string",
                            "description": "æ–°çš„å€¼"
                        }
                    },
                    "required": ["row_index", "column", "value"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "add_row",
                "description": "å‘è¡¨æ ¼æ·»åŠ ä¸€è¡Œæ•°æ®ã€‚å½“ç”¨æˆ·è¯´'æ·»åŠ ä¸€è¡Œ'ã€'åŠ ä¸ŠXX'æ—¶è°ƒç”¨",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "table_id": {
                            "type": "string",
                            "description": "ç›®æ ‡è¡¨æ ¼IDã€‚å¦‚æœä¸æŒ‡å®šï¼Œé»˜è®¤æ“ä½œå½“å‰æ¿€æ´»çš„è¡¨æ ¼"
                        },
                        "data": {
                            "type": "object",
                            "description": "è¡Œæ•°æ®ï¼Œå¦‚ {\"å•†å“åç§°\": \"è‹¹æœ\", \"æ•°é‡\": 10}"
                        }
                    },
                    "required": []
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "delete_row",
                "description": "åˆ é™¤è¡¨æ ¼ä¸­çš„ä¸€è¡Œã€‚å½“ç”¨æˆ·è¯´'åˆ é™¤ç¬¬Xè¡Œ'ã€'å»æ‰æœ€åä¸€è¡Œ'æ—¶è°ƒç”¨",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "table_id": {
                            "type": "string",
                            "description": "ç›®æ ‡è¡¨æ ¼IDã€‚å¦‚æœä¸æŒ‡å®šï¼Œé»˜è®¤æ“ä½œå½“å‰æ¿€æ´»çš„è¡¨æ ¼"
                        },
                        "row_index": {
                            "type": "integer",
                            "description": "è¡Œå·ï¼ˆä»1å¼€å§‹ï¼‰ï¼Œ-1è¡¨ç¤ºæœ€åä¸€è¡Œ"
                        }
                    },
                    "required": ["row_index"]
                }
            }
        }
    ]


async def _execute_tool(
    tool_name: str,
    args: Dict,
    client_id: str,
    table_id: str,
    table_context: dict,
    fast_tools
) -> str:
    """æ‰§è¡Œå·¥å…·å¹¶è¿”å›ç»“æœ"""
    
    if tool_name == "create_table":
        title = args.get("title", "æ–°è¡¨æ ¼")
        # æ¨é€åˆ›å»ºè¡¨æ ¼äº‹ä»¶
        await push_event(client_id, EventType.TOOL_CALL, {
            "tool": "create_table",
            "params": {"title": title}
        })
        return f"âœ… å·²ä¸ºä½ åˆ›å»ºè¡¨æ ¼ã€Œ{title}ã€"
    
    elif tool_name == "query_product":
        product_name = args.get("product_name", "")
        if not product_name:
            return "â“ è¯·å‘Šè¯‰æˆ‘è¦æŸ¥è¯¢ä»€ä¹ˆå•†å“"
        
        products = fast_tools.quick_product_lookup(product_name, limit=5)
        
        if products:
            result_lines = [f"ğŸ” å…³äºã€Œ{product_name}ã€çš„æŸ¥è¯¢ç»“æœï¼š\n"]
            for p in products[:5]:
                price_info = f"Â¥{p['price']}" if p['price'] > 0 else "æ— ä»·æ ¼ä¿¡æ¯"
                result_lines.append(f"â€¢ **{p['name']}** - {p['unit']} - {price_info}")
                if p.get('spec'):
                    result_lines[-1] += f" ({p['spec']})"
            return "\n".join(result_lines)
        else:
            return f"ğŸ” åœ¨å•†å“åº“ä¸­æœªæ‰¾åˆ°ã€Œ{product_name}ã€ç›¸å…³å•†å“"
    
    elif tool_name == "calculate_total":
        if not table_context or not table_context.get("rows"):
            return "ğŸ“Š å½“å‰æ²¡æœ‰è¡¨æ ¼æ•°æ®å¯ä¾›è®¡ç®—ã€‚è¯·å…ˆé€‰æ‹©ä¸€ä¸ªè¡¨æ ¼ã€‚"
        
        from app.agents.consultative_agent import consultative_agent
        operation = args.get("operation", "total")
        calc_result = await consultative_agent.calculate(operation, table_context)
        return calc_result.answer
    
    elif tool_name == "modify_cell":
        row_index = args.get("row_index", 1) - 1  # è½¬ä¸º 0-based
        column = args.get("column", "")
        value = args.get("value", "")
        target_table_id = args.get("table_id")
        
        # ä¼˜å…ˆä½¿ç”¨å·¥å…·å‚æ•°ä¸­çš„ table_idï¼Œå…¶æ¬¡ä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­çš„è¡¨æ ¼IDï¼Œæœ€åä½¿ç”¨ table_id å‚æ•°
        context_table_id = None
        if table_context:
            context_table_id = table_context.get("activeTableId") or table_context.get("id")
            
        final_table_id = target_table_id or context_table_id or table_id
        
        if not final_table_id:
            return "â“ è¯·å…ˆé€‰æ‹©è¦ä¿®æ”¹çš„è¡¨æ ¼"
        
        # æ¨é€ä¿®æ”¹äº‹ä»¶
        await push_event(client_id, EventType.TOOL_CALL, {
            "tool": "update_cell",
            "params": {
                "table_id": final_table_id,
                "row_index": row_index,
                "key": column,
                "value": value
            }
        })
        return f"âœ… å·²å°†ç¬¬ {row_index + 1} è¡Œçš„ã€Œ{column}ã€æ”¹ä¸ºã€Œ{value}ã€"
    
    elif tool_name == "smart_fill":
        from app.services.aliyun_llm import llm_service
        
        text = args.get("text", "")
        target_table_id = args.get("table_id")
        
        context_table_id = None
        if table_context:
            context_table_id = table_context.get("activeTableId") or table_context.get("id")
            
        final_table_id = target_table_id or context_table_id or table_id
        
        if not final_table_id:
            # å¦‚æœæ²¡æœ‰è¡¨æ ¼ï¼Œç”Ÿæˆä¸€ä¸ªä¸´æ—¶çš„ ID
            final_table_id = f"table_{generate_trace_id()[:8]}"
            
        # 1. è°ƒç”¨æå–æ¨¡å‹ (Turbo)
        logger.info(f"[SmartFill] Extracting from text: {text[:50]}...")
        extraction_prompt = UNSTRUCTURED_EXTRACTION_PROMPT.format(text=text)
        
        try:
            # ä½¿ç”¨ Turbo æ¨¡å‹è¿›è¡Œæå–
            extracted_json_str = await llm_service.call_turbo_model(
                messages=[{"role": "user", "content": extraction_prompt}],
                temperature=0.1
            )
            import json
            extracted_rows = json.loads(extracted_json_str)
            
            if not isinstance(extracted_rows, list):
                extracted_rows = [extracted_rows]
                
            logger.info(f"[SmartFill] Extracted {len(extracted_rows)} rows")
            
            if not extracted_rows:
                return "âš ï¸ æœªèƒ½ä»æ–‡æœ¬ä¸­æå–åˆ°æœ‰æ•ˆæ•°æ®"

            # 2. é€è¡Œæ¨é€
            valid_count = 0
            for idx, raw_row in enumerate(extracted_rows):
                # æ˜ å°„åˆ°æ¨¡æ¿
                normalized_row = map_row_to_template(raw_row)
                if "è¯†åˆ«å•†å“" not in normalized_row and "å“å" in raw_row:
                    normalized_row["è¯†åˆ«å•†å“"] = raw_row["å“å"]
                
                # æ¨é€
                await push_row(client_id, final_table_id, normalized_row, idx)
                valid_count += 1
                
                # 3. è§¦å‘è½»é‡çº§æ ¡å¯¹
                try:
                    product_name = normalized_row.get("è¯†åˆ«å•†å“", "")
                    if product_name:
                        from app.services.knowledge_base import vector_store
                        from app.services.handwriting_hints import CalibrationThresholds
                        
                        result = await vector_store.calibrate(str(product_name))
                        confidence_level = CalibrationThresholds.get_level(result.confidence)
                        
                        calibrated_field = "è®¢å•å•†å“"
                        note = ""
                        
                        if confidence_level == 'high':
                            await push_event(client_id, EventType.CELL_UPDATE, {
                                "table_id": final_table_id,
                                "row_index": idx,
                                "col_key": calibrated_field,
                                "value": result.calibrated
                            })
                        elif confidence_level == 'medium':
                            if result.suggestion:
                                note = result.suggestion
                        elif confidence_level == 'low':
                            note = f"â“å»ºè®®: {', '.join(result.candidates[:3])}" if result.candidates else "â“æœªæ‰¾åˆ°"
                        
                        if note:
                            await push_event(client_id, EventType.CELL_UPDATE, {
                                "table_id": final_table_id,
                                "row_index": idx,
                                "col_key": calibrated_field,
                                "value": note
                            })
                            await push_event(client_id, EventType.CALIBRATION_NOTE, {
                                "table_id": final_table_id,
                                "row_index": idx,
                                "note": note,
                                "severity": "warning"
                            })
                except Exception as e:
                    logger.warning(f"[SmartFill] Calibration error for row {idx}: {e}")

            return f"âœ… å·²æˆåŠŸæå–å¹¶å½•å…¥ {valid_count} æ¡æ•°æ®"
            
        except Exception as e:
            logger.error(f"[SmartFill] Failed: {e}")
            return f"âŒ æå–å¤±è´¥: {str(e)}"

    elif tool_name == "add_row":
        data = args.get("data", {})
        target_table_id = args.get("table_id")
        
        context_table_id = None
        if table_context:
            context_table_id = table_context.get("activeTableId") or table_context.get("id")
            
        final_table_id = target_table_id or context_table_id or table_id
        
        if not final_table_id:
            return "â“ è¯·å…ˆé€‰æ‹©è¦æ·»åŠ æ•°æ®çš„è¡¨æ ¼"
        
        await push_event(client_id, EventType.TOOL_CALL, {
            "tool": "add_row",
            "params": {
                "table_id": final_table_id,
                "data": data
            }
        })
        return f"âœ… å·²æ·»åŠ ä¸€è¡Œæ•°æ®"
    
    elif tool_name == "delete_row":
        row_index = args.get("row_index", -1)
        if row_index > 0:
            row_index -= 1  # è½¬ä¸º 0-based
        
        target_table_id = args.get("table_id")
        context_table_id = None
        if table_context:
            context_table_id = table_context.get("activeTableId") or table_context.get("id")
            
        final_table_id = target_table_id or context_table_id or table_id
        
        if not final_table_id:
            return "â“ è¯·å…ˆé€‰æ‹©è¦åˆ é™¤æ•°æ®çš„è¡¨æ ¼"
        
        await push_event(client_id, EventType.TOOL_CALL, {
            "tool": "delete_row",
            "params": {
                "table_id": final_table_id,
                "row_index": row_index
            }
        })
        row_desc = "æœ€åä¸€è¡Œ" if row_index == -1 else f"ç¬¬ {row_index + 1} è¡Œ"
        return f"âœ… å·²åˆ é™¤{row_desc}"
    
    else:
        return f"â“ æœªçŸ¥å·¥å…·: {tool_name}"


async def action_agent(state: AgentState) -> AgentState:
    """
    æ“ä½œ Agent - ä½¿ç”¨ AgentTools å¤„ç†å¢åˆ æ”¹æ“ä½œ
    
    æµç¨‹ï¼š
    1. ä½¿ç”¨æ„å›¾åˆ†ç±»å™¨æå–çš„å‚æ•°ï¼ˆå¦‚æœæœ‰ï¼‰
    2. å‚æ•°ä¸å®Œæ•´æ—¶è°ƒç”¨ LLM è¡¥å……
    3. æ‰§è¡Œå·¥å…·å¹¶æ¨é€ç»“æœ
    """
    from app.services.aliyun_llm import llm_service
    from app.agents.tools.agent_tools import AgentTools, agent_tools, ToolCall
    from app.agents.context_manager import context_manager
    
    logger.info(f"[ActionAgent] Processing task {state['task_id']}")
    
    text = state.get("text_content", "")
    client_id = state["client_id"]
    
    try:
        # è·å–ä¸Šä¸‹æ–‡
        ctx = context_manager.get_context(client_id)
        
        # ç”Ÿæˆå·¥å…·å®šä¹‰ Prompt
        tools_prompt = agent_tools.generate_tools_prompt()
        
        # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        context_info = ""
        if ctx.current_table_id:
            context_info += f"\nå½“å‰è¡¨æ ¼: {ctx.current_table_id}"
        if ctx.current_row_index is not None:
            context_info += f"\nå½“å‰é€‰ä¸­è¡Œ: ç¬¬{ctx.current_row_index + 1}è¡Œ"
        
        system_prompt = f"""ä½ æ˜¯æ™ºèƒ½è¡¨å•æ“ä½œåŠ©æ‰‹ã€‚åˆ†æç”¨æˆ·æŒ‡ä»¤ï¼Œè¾“å‡º JSON å·¥å…·è°ƒç”¨ã€‚

{tools_prompt}

{context_info}

é‡è¦è§„åˆ™ï¼š
1. "ç¬¬ä¸€è¡Œ"å¯¹åº” row_index=0ï¼Œ"ç¬¬äºŒè¡Œ"å¯¹åº” row_index=1
2. å¦‚æœç¼ºå°‘å¿…è¦ä¿¡æ¯ï¼Œä½¿ç”¨ clarify å·¥å…·è¯¢é—®
3. å­—æ®µåä½¿ç”¨ä¸­æ–‡ï¼ˆå¦‚"å•†å“åç§°"ã€"æ•°é‡"ã€"å•ä»·"ï¼‰"""
        
        # è°ƒç”¨ LLM è·å–å·¥å…·è°ƒç”¨
        response = await llm_service.call_main_model([
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": text}
        ])
        
        # è§£æå·¥å…·è°ƒç”¨
        tool_call = agent_tools.parse_tool_call(response)
        
        if tool_call:
            logger.info(f"[ActionAgent] Tool call: {tool_call.tool}, params: {tool_call.params}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ clarifyï¼ˆéœ€è¦æ¾„æ¸…ï¼‰
            if tool_call.tool == "clarify":
                question = tool_call.params.get("question", "è¯·æä¾›æ›´å¤šä¿¡æ¯")
                await push_event(client_id, EventType.CHAT_MESSAGE, {
                    "role": "agent",
                    "content": question
                })
                ctx.add_agent_message(question)
            else:
                # æ‰§è¡Œå·¥å…·
                execution_context = {
                    "current_table_id": ctx.current_table_id,
                    "current_row_index": ctx.current_row_index,
                }
                result = await agent_tools.execute_tool(tool_call, execution_context)
                
                if result.get("success"):
                    # æ¨é€å·¥å…·è°ƒç”¨ç»™å‰ç«¯
                    await push_event(client_id, EventType.TOOL_CALL, {
                        "tool": tool_call.tool,
                        "params": tool_call.params
                    })
                    
                    # ç”Ÿæˆç¡®è®¤æ¶ˆæ¯
                    confirm_msg = agent_tools.generate_confirm_message(tool_call, result)
                    await push_event(client_id, EventType.CHAT_MESSAGE, {
                        "role": "agent",
                        "content": confirm_msg
                    })
                    ctx.add_agent_message(confirm_msg, tool_call=tool_call.to_dict())
                else:
                    # æ‰§è¡Œå¤±è´¥
                    error_msg = result.get("message", "æ“ä½œæ‰§è¡Œå¤±è´¥")
                    await push_event(client_id, EventType.CHAT_MESSAGE, {
                        "role": "agent",
                        "content": f"âŒ {error_msg}"
                    })
        else:
            # ä¸æ˜¯å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å› LLM å“åº”
            await push_event(client_id, EventType.CHAT_MESSAGE, {
                "role": "agent",
                "content": response
            })
            ctx.add_agent_message(response)
        
    except Exception as e:
        logger.error(f"[ActionAgent] Failed: {str(e)}")
        state["error"] = str(e)
        await push_event(client_id, EventType.CHAT_MESSAGE, {
            "role": "agent",
            "content": f"æŠ±æ­‰ï¼Œæ“ä½œæ‰§è¡Œå‡ºé”™: {str(e)}"
        })
    
    state["next_node"] = "end"
    return state


async def end_node(state: AgentState) -> AgentState:
    """
    ç»“æŸèŠ‚ç‚¹ - å‘é€ä»»åŠ¡å®Œæˆ/å¤±è´¥äº‹ä»¶
    """
    task_id = state["task_id"]
    client_id = state["client_id"]
    error = state.get("error")
    table_id = state.get("table_id")
    
    if error:
        await push_error(client_id, task_id, error)
        await push_event(client_id, EventType.TASK_FINISH, {
            "task_id": task_id,
            "status": "error",
            "error": error,
            "table_id": table_id,
        })
    else:
        await push_event(client_id, EventType.TASK_FINISH, {
            "task_id": task_id,
            "status": "success",
            "table_id": table_id,
        })
    
    logger.info(f"[End] Task {task_id} finished, error={error}")
    return state


# ========== æ¡ä»¶è·¯ç”± ==========

def route_by_next_node(state: AgentState) -> str:
    """æ ¹æ® next_node è·¯ç”±"""
    return state.get("next_node", "end")


# ========== æ„å»ºå·¥ä½œæµ ==========

def create_workflow() -> StateGraph:
    """åˆ›å»º LangGraph å·¥ä½œæµ"""
    
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
    workflow.add_node("router", router_node)
    workflow.add_node("ocr_node", ocr_node)
    workflow.add_node("excel_node", excel_node)
    workflow.add_node("word_node", word_node)
    workflow.add_node("llm_node", llm_node)
    workflow.add_node("push_rows_node", push_rows_node)
    workflow.add_node("calibration_node", calibration_node)
    workflow.add_node("audio_node", audio_node)
    workflow.add_node("action_agent", action_agent)
    workflow.add_node("chat_node", chat_node)
    workflow.add_node("end", end_node)
    
    # è®¾ç½®å…¥å£
    workflow.set_entry_point("router")
    
    # Router çš„æ¡ä»¶è¾¹
    workflow.add_conditional_edges(
        "router",
        route_by_next_node,
        {
            "ocr_node": "ocr_node",
            "excel_node": "excel_node",
            "word_node": "word_node",
            "audio_node": "audio_node",
            "chat_node": "chat_node",
            "end": "end"
        }
    )
    
    # OCR -> LLM
    workflow.add_conditional_edges(
        "ocr_node",
        route_by_next_node,
        {"llm_node": "llm_node", "end": "end"}
    )
    
    # Excel -> LLM (ç»Ÿä¸€æ¸…æ´—)
    workflow.add_conditional_edges(
        "excel_node",
        route_by_next_node,
        {"llm_node": "llm_node", "end": "end"}
    )
    
    # Word -> LLM (ç»Ÿä¸€æ¸…æ´—)
    workflow.add_conditional_edges(
        "word_node",
        route_by_next_node,
        {"llm_node": "llm_node", "end": "end"}
    )
    
    # LLM -> Push
    workflow.add_conditional_edges(
        "llm_node",
        route_by_next_node,
        {"push_rows_node": "push_rows_node", "end": "end"}
    )
    
    # Push -> Calibration
    workflow.add_conditional_edges(
        "push_rows_node",
        route_by_next_node,
        {"calibration_node": "calibration_node", "end": "end"}
    )
    
    # Calibration -> End
    workflow.add_edge("calibration_node", "end")
    
    # Audio -> End
    workflow.add_edge("audio_node", "end")
    
    # Chat -> Action Agent or End
    workflow.add_conditional_edges(
        "chat_node",
        route_by_next_node,
        {"action_agent": "action_agent", "end": "end"}
    )
    
    # Action Agent -> End
    workflow.add_edge("action_agent", "end")
    
    # End -> END
    workflow.add_edge("end", END)
    
    logger.info("LangGraph workflow created (ComfyUI style)")
    return workflow


# ç¼–è¯‘å·¥ä½œæµ
agent_graph = create_workflow().compile()


# ========== æ‰§è¡Œå…¥å£ ==========

async def run_task(
    task_id: str,
    client_id: str,
    task_type: str,
    file_content: bytes = None,
    file_name: str = None,
    text_content: str = None,
    table_id: str = None,
    table_context: Dict[str, Any] = None,  # è¡¨æ ¼ä¸Šä¸‹æ–‡ï¼ˆç”¨äºå’¨è¯¢åˆ†æï¼‰
) -> None:
    """
    æ‰§è¡Œä»»åŠ¡ - ä¾› endpoints è°ƒç”¨
    
    Args:
        task_id: ä»»åŠ¡ ID
        client_id: å®¢æˆ·ç«¯ ID
        task_type: ä»»åŠ¡ç±»å‹ (extract/audio/chat)
        file_content: æ–‡ä»¶å†…å®¹
        file_name: æ–‡ä»¶å
        text_content: æ–‡æœ¬å†…å®¹
        table_id: ç›®æ ‡è¡¨æ ¼ ID
        table_context: è¡¨æ ¼ä¸Šä¸‹æ–‡ï¼ˆç”¨äºå’¨è¯¢åˆ†æï¼‰{title, rows, schema, metadata}
    """
    initial_state: AgentState = {
        "task_id": task_id,
        "client_id": client_id,
        "task_type": task_type,
        "file_content": file_content,
        "file_name": file_name,
        "text_content": text_content,
        "ocr_text": None,
        "ocr_notes": [],
        "content_type": None,
        "extracted_rows": [],
        "table_id": table_id,
        "table_context": table_context,  # ä¼ é€’è¡¨æ ¼ä¸Šä¸‹æ–‡
        "next_node": None,
        "error": None
    }
    
    try:
        await agent_graph.ainvoke(initial_state)
    except Exception as e:
        logger.error(f"[RunTask] Task {task_id} failed: {str(e)}")
        await push_error(client_id, task_id, str(e))
