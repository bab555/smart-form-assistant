"""
å®Œæ•´æµ‹è¯•é˜¿é‡Œäº‘ DashScope æ‰€æœ‰æ¨¡å‹è¿æ¥
"""
import asyncio
import sys
import base64
sys.path.insert(0, '.')

from dotenv import load_dotenv
load_dotenv()

import dashscope
from dashscope import Generation, MultiModalConversation
from dashscope.audio.asr import Transcription
from app.core.config import settings
from app.services.aliyun_llm import llm_service

# è®¾ç½® API Key
dashscope.api_key = settings.ALIYUN_ACCESS_KEY_ID


async def test_llm_main():
    """æµ‹è¯•ä¸»æ§å¤§æ¨¡å‹ Qwen-Max"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯• 1: ä¸»æ§å¤§æ¨¡å‹ (Qwen-Max)")
    print("=" * 60)
    
    try:
        messages = [{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"}]
        response = await llm_service.call_main_model(messages, max_tokens=100)
        print(f"âœ… å“åº”: {response[:100]}...")
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return False


async def test_llm_turbo():
    """æµ‹è¯•æ ¡å¯¹å¤§æ¨¡å‹ Qwen-Turbo"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯• 2: æ ¡å¯¹å¤§æ¨¡å‹ (Qwen-Turbo)")
    print("=" * 60)
    
    try:
        prompt = "è¯·æ ¡å¯¹è¿™ä¸ªè¯ï¼šè‹¹æœï¼Œæ˜¯å¦æ˜¯æ°´æœåç§°ï¼Ÿåªå›ç­”æ˜¯æˆ–å¦"
        response = await llm_service.call_calibration_model(prompt)
        print(f"âœ… å“åº”: {response}")
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return False


def test_multimodal():
    """æµ‹è¯•å¤šæ¨¡æ€æ¨¡å‹ Qwen-VL"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯• 3: å¤šæ¨¡æ€æ¨¡å‹ (Qwen-VL)")
    print("=" * 60)
    
    try:
        # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡ URL
        test_image_url = "https://dashscope.oss-cn-beijing.aliyuncs.com/images/dog_and_girl.jpeg"
        
        messages = [{
            "role": "user",
            "content": [
                {"image": test_image_url},
                {"text": "è¯·ç”¨ä¸€å¥è¯æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"}
            ]
        }]
        
        response = MultiModalConversation.call(
            model="qwen-vl-plus",
            messages=messages
        )
        
        if response.status_code == 200:
            content = response.output.choices[0].message.content[0]["text"]
            print(f"âœ… å“åº”: {content[:100]}...")
            return True
        else:
            print(f"âŒ å¤±è´¥: {response.code} - {response.message}")
            return False
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return False


def test_asr():
    """æµ‹è¯•è¯­éŸ³è¯†åˆ« ASR (Paraformer)"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯• 4: è¯­éŸ³è¯†åˆ« ASR (Paraformer)")
    print("=" * 60)
    
    try:
        # ä½¿ç”¨é˜¿é‡Œäº‘ç¤ºä¾‹éŸ³é¢‘
        test_audio_url = "https://dashscope.oss-cn-beijing.aliyuncs.com/samples/audio/paraformer/hello_world_female2.wav"
        
        response = Transcription.call(
            model="paraformer-v2",
            file_urls=[test_audio_url]
        )
        
        if response.status_code == 200:
            # å¼‚æ­¥ä»»åŠ¡ï¼Œè·å–ä»»åŠ¡ID
            task_id = response.output.get('task_id')
            print(f"âœ… ASR ä»»åŠ¡å·²æäº¤ï¼ŒTask ID: {task_id}")
            
            # ç­‰å¾…ç»“æœ
            import time
            for _ in range(10):
                time.sleep(1)
                result = Transcription.fetch(task=task_id)
                if result.output.get('task_status') == 'SUCCEEDED':
                    transcripts = result.output.get('results', [])
                    if transcripts:
                        text = transcripts[0].get('transcription_url', 'æŸ¥çœ‹URLè·å–ç»“æœ')
                        print(f"âœ… ASR è¯†åˆ«å®Œæˆ!")
                    return True
                elif result.output.get('task_status') == 'FAILED':
                    print(f"âŒ ASR ä»»åŠ¡å¤±è´¥")
                    return False
            print(f"â³ ASR ä»»åŠ¡ä»åœ¨å¤„ç†ä¸­...")
            return True
        else:
            print(f"âŒ å¤±è´¥: {response.code} - {response.message}")
            return False
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return False


def test_ocr_via_vl():
    """æµ‹è¯• OCR (é€šè¿‡ Qwen-VL å¤šæ¨¡æ€å®ç°)"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯• 5: OCR æ–‡å­—è¯†åˆ« (Qwen-VL)")
    print("=" * 60)
    
    try:
        # ä½¿ç”¨ä¸€ä¸ªåŒ…å«æ–‡å­—çš„æµ‹è¯•å›¾ç‰‡
        test_image_url = "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20241022/emyrja/dog_and_girl.jpeg"
        
        messages = [{
            "role": "user",
            "content": [
                {"image": test_image_url},
                {"text": "å¦‚æœå›¾ç‰‡ä¸­æœ‰æ–‡å­—ï¼Œè¯·è¯†åˆ«å‡ºæ¥ï¼›å¦‚æœæ²¡æœ‰æ–‡å­—ï¼Œè¯·è¯´æ˜å›¾ç‰‡å†…å®¹"}
            ]
        }]
        
        response = MultiModalConversation.call(
            model="qwen-vl-plus",
            messages=messages
        )
        
        if response.status_code == 200:
            content = response.output.choices[0].message.content[0]["text"]
            print(f"âœ… å“åº”: {content[:150]}...")
            return True
        else:
            print(f"âŒ å¤±è´¥: {response.code} - {response.message}")
            return False
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return False


async def test_embedding():
    """æµ‹è¯• Embedding å‘é‡æ¨¡å‹"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯• 6: Embedding å‘é‡ (text-embedding-v2)")
    print("=" * 60)
    
    try:
        text = "çº¢å¯Œå£«è‹¹æœ"
        embedding = await llm_service.get_embedding(text)
        print(f"âœ… ç»´åº¦: {len(embedding)}")
        print(f"âœ… å‰5ä¸ªå€¼: {[round(v, 4) for v in embedding[:5]]}")
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return False


async def test_calibration():
    """æµ‹è¯•æ ¡å‡†æµç¨‹ï¼ˆå‘é‡ + Turbo äºŒæ¬¡ç¡®è®¤ï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯• 7: æ ¡å‡†æµç¨‹ (å‘é‡ + Turbo äºŒæ¬¡ç¡®è®¤)")
    print("=" * 60)
    
    try:
        from app.services.knowledge_base import vector_store
        
        # å…ˆç¡®ä¿çŸ¥è¯†åº“å·²åˆå§‹åŒ–
        if vector_store.index is None:
            print("â³ æ­£åœ¨åˆå§‹åŒ–çŸ¥è¯†åº“...")
            await vector_store.initialize()
        
        # æµ‹è¯•ç”¨ä¾‹ï¼šæ¨¡æ‹Ÿ OCR è¯†åˆ«çš„æ¨¡ç³Šæ–‡æœ¬
        test_cases = [
            ("çº¢å¯ŒåœŸè‹¹æœ", "product"),   # é”™åˆ«å­—ï¼šå£« -> åœŸ
            ("è‹¹æœ", "product"),         # æ­§ä¹‰ï¼šå¤šç§è‹¹æœ
            ("åƒå…‹", "unit"),            # å•ä½
        ]
        
        for raw_text, category in test_cases:
            print(f"\n  è¾“å…¥: '{raw_text}' (ç±»åˆ«: {category})")
            result, confidence, is_amb, candidates = await vector_store.calibrate_text(raw_text, category)
            print(f"  è¾“å‡º: '{result}' (ç½®ä¿¡åº¦: {confidence:.2f}, æ­§ä¹‰: {is_amb})")
            if candidates:
                print(f"  å€™é€‰: {candidates}")
        
        print("\nâœ… æ ¡å‡†æµç¨‹æµ‹è¯•å®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    print("\n" + "ğŸš€" * 20)
    print("   é˜¿é‡Œäº‘ DashScope å…¨æ¨¡å‹è¿æ¥æµ‹è¯•")
    print("ğŸš€" * 20 + "\n")
    
    results = {}
    
    # æµ‹è¯•å„æ¨¡å‹
    results["LLM (Qwen-Max)"] = await test_llm_main()
    results["LLM Turbo (Qwen-Turbo)"] = await test_llm_turbo()
    results["å¤šæ¨¡æ€ (Qwen-VL)"] = test_multimodal()
    results["ASR è¯­éŸ³è¯†åˆ«"] = test_asr()
    results["OCR via VL"] = test_ocr_via_vl()
    results["Embedding"] = await test_embedding()
    results["æ ¡å‡†æµç¨‹ (æ ¸å¿ƒ)"] = await test_calibration()
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    all_pass = True
    for name, passed in results.items():
        status = "âœ… æ­£å¸¸" if passed else "âŒ å¤±è´¥"
        print(f"  {name:25} {status}")
        if not passed:
            all_pass = False
    
    print("=" * 60)
    if all_pass:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹è”è°ƒäº†ã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ API Key å’Œç½‘ç»œè¿æ¥ã€‚")
    print("\nğŸ’¡ æ ¡å‡†æµç¨‹è¯´æ˜ï¼šå‘é‡æ£€ç´¢ â†’ Turbo äºŒæ¬¡ç¡®è®¤ â†’ æœ€ç»ˆç»“æœ")
    
    return all_pass


if __name__ == "__main__":
    asyncio.run(main())
