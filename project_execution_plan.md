# 智能多模态识别与填报系统 - 项目执行文档

## 1. 项目概述
本项目旨在构建一个基于大模型（LLM）总控的智能填报系统。用户可以通过语音或手写（图像）输入信息，系统利用多模态技术（ASR、OCR、视觉大模型）自动提取数据，经由大模型利用**动态知识库技能（Agent Skills）**进行逻辑校准后，自动填充前端表单，最终生成标准化JSON数据并同步至宿主系统。

本系统设计为可嵌入式组件，能够集成到现有网站中，不独立维护用户权限体系。

---

## 2. 系统架构设计

### 2.1 后端核心逻辑：LangChain 工作流 (LangChain Workflows)
后端采用 LangChain / LangGraph 构建**条件路由工作流**，根据用户输入类型进入不同的处理分支：

#### **总控路由层 (Master Router)**
*   **输入**: 图片 或 语音/文本。
*   **判断**:
    *   是图片 -> 判断是“手写单据”还是“标准打印文档” -> 进入 **视觉处理流**。
    *   是语音 -> 进入 **语音交互流**。

#### **工作流分支 1: 视觉处理流 (Visual Processing Flow)**
*   **分支 1.1: 手写单据 (Handwritten)**
    *   **特点**: 字迹潦草，噪声大，需要视觉语义辅助。
    *   **Step 1**: 并行调用 **OCR 引擎** (提取文字骨架) + **多模态 V-LLM** (Qwen-VL, 提取版面结构与视觉特征)。
    *   **Step 2**: **校准模型 (Calibration Agent)** 介入。
        *   调用 `lookup_standard_entity` 技能，结合 OCR 文本与 V-LLM 语义，在向量知识库中检索标准值。
    *   **Step 3**: 填表模型生成标准化 JSON。

*   **分支 1.2: 打印文档 (Printed Document)**
    *   **特点**: 字体清晰，格式规整。
    *   **Step 1**: 仅调用 **OCR 引擎** (高精度模式)。
    *   **Step 2**: **校准模型 (Calibration Agent)** 介入。
        *   主要进行格式化清洗（日期、金额格式修正），并在必要时查阅知识库。
    *   **Step 3**: 填表模型生成标准化 JSON。

#### **工作流分支 2: 语音交互流 (Audio/Interaction Flow)**
*   **特点**: 用户通常通过语音进行**指令操作**或**补充说明**，而非通篇朗读表格。
*   **Step 1**: **ASR 引擎** (阿里/Whisper) 将语音转为文本。
*   **Step 2**: **主控模型 (Master Agent)** 分析意图。
    *   **情况 A (操作指令)**: 用户说“把第一行的数量改成50”。 -> 触发 `update_form_field` 工具 -> 修改前端 JSON。
    *   **情况 B (普通对话)**: 用户说“这个系统怎么用？” -> 触发 `chat_response` -> 返回文本回答。
    *   **情况 C (补充填报)**: 用户说“备注里加上：加急配送”。 -> 触发 `update_form_field` 工具 -> 填入备注字段。

#### **工作流分支 3: 异常反馈与人机回环 (Feedback Loop)**
*   **触发条件**: 校准模型在知识库中找到多个相似度极高的候选值（例如：识别为“红烧牛肉”，库里有“红烧牛肉面”和“红烧牛肉粉”，置信度差异 < 5%）。
*   **动作**:
    1.  校准模型返回标记：`Status: AMBIGUOUS`, `Options: ["面", "粉"]`。
    2.  **主控模型** 接管，生成自然语言提问：“识别结果有歧义，请问是‘牛肉面’还是‘牛肉粉’？”
    3.  用户回答（语音/文本） -> 进入 **语音交互流** -> 明确意图 -> 修正表格。

---

### 2.2 技术栈方案
*   **前端 (Frontend)**:
    *   语言: **TypeScript** (React)
    *   功能: Chat 界面 + **可编辑**动态表格 (Editable Data Grid)。支持用户在 AI 填完后手动点击单元格修改。
*   **后端 (Backend)**:
    *   语言: **Python** (FastAPI)
    *   框架: **LangChain / LangGraph** (用于构建上述状态机工作流)。
    *   **AI 能力**: 统一调用 **阿里云 API** (OCR, ASR, Qwen-Max/VL)。
*   **数据知识库**:
    *   **向量化存储**: MySQL -> 提取标准词 -> FAISS 向量索引 (作为 Agent 的只读技能手册)。

---

## 3. 功能模块详解

### 3.1 动态词典技能 (Database as a Skill)
*   **数据源**: 宿主数据库的标准表（商品名、分类）。
*   **技能定义**: `lookup_standard_entity`。
*   **逻辑**: OCR 文本 -> 向量检索 -> Top-K 候选 -> 语义重排序 -> 返回标准值。

### 3.2 交互设计细节
*   **主动修改**: 表格组件（如 Ag-Grid 或 AntD Table）必须保持 Edit Mode。当 AI 填入数据后，用户可以直接点击修改。
*   **修改反馈**: 用户手动修改表格后，前端应静默发送一个事件给后端：“用户把字段 A 从 X 改成了 Y”。(可选：用于后台优化模型，暂不强制)。

---

## 4. 接口与数据交互设计

### 4.1 嵌入协议 (Embedding Protocol)
*   宿主网站通过 SDK 传入 `template_id` 和 `token`。

### 4.2 后端 API 规划
| 方法 | 路径 | 描述 |
| :--- | :--- | :--- |
| POST | `/api/workflow/visual` | **视觉流入口**: 上传图片 -> 路由判断(手写/打印) -> OCR/V-LLM -> 校准 -> 返回 JSON |
| POST | `/api/workflow/audio` | **语音流入口**: 上传音频 -> ASR -> 意图识别 -> 返回 Action (修改表格/回复文本) |
| POST | `/api/sync/knowledge` | 触发知识库同步 (MySQL -> Vector) |

### 4.3 环境变量 (.env)
```ini
# 阿里云配置
ALIYUN_API_KEY=your_api_key
ALIYUN_APP_KEY=your_app_key (语音服务)

# 宿主数据库 (只读权限)
DB_HOST=localhost
DB_USER=readonly_user
```

---

## 5. 开发执行计划 (Roadmap)

### 第一阶段：知识库与基础架构 (Week 1)
*   [ ] 实现 MySQL 数据抽取与 FAISS 向量化构建。
*   [ ] 搭建 FastAPI + LangChain 环境。
*   [ ] 定义 `lookup_standard_entity` 工具。

### 第二阶段：视觉处理工作流 (Week 2)
*   [ ] 实现 **分支 1.1 (手写)**: 集成 Qwen-VL + OCR + 校准逻辑。
*   [ ] 实现 **分支 1.2 (打印)**: 集成纯 OCR + 格式化逻辑。
*   [ ] 开发“路由层”：简单的图像分类或让 V-LLM 判断图片类型。

### 第三阶段：语音与主控逻辑 (Week 3)
*   [ ] 实现 **分支 2 (语音)**: 集成 ASR + 意图识别 Prompts。
*   [ ] 实现 **分支 3 (反馈)**: 处理歧义状态，生成澄清问题。

### 第四阶段：前端集成 (Week 4)
*   [ ] 开发 React 聊天组件 + 可编辑表格组件。
*   [ ] 联调：语音指令控制表格修改。

---

## 6. 确认事项 (已更新)
1.  **数据库类型**: **MySQL**。
2.  **AI 策略**: 全云端 (阿里云 Qwen + OCR + ASR)，本地轻量化。
3.  **校准逻辑**: **Database as a Skill** (向量检索校准)。
4.  **工作流**: 明确区分 **视觉识别流** (填表为主) 和 **语音交互流** (指令/对话为主)。
